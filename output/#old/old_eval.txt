"""
# for each article listed in the ground truth, check what datasets are from that article
UIDs = []
for index, row in ground_truth.iterrows():
    article_id = row["Source Page"]
    # for rows with source_url = article_id, check the rows
    rows = eval_output[eval_output["source_url"] == article_id]
    rows_2 = eval_output_2[eval_output_2["source_url"] == article_id]
    # if there are no rows, continue
    if rows.empty and rows_2.empty:
        continue
    # if there are rows, print the article id and the dataset identifiers, dataset website and repo
    print(f"article_id: {article_id}")
    for i in range(3):
        item = {"article_id": article_id}
        dataset = row[f"Dataset {i + 1}: UID Provided "]
        repo = row[f"Dataset {i + 1}: Repository Name Provided"]
        link = row[f"Dataset {i + 1}: Link Provided"]
        if type(dataset) == float:
            continue
        if ' and ' in dataset:
            dataset = dataset.split(' and ')
            for id in dataset:
                item_copy = item.copy()  # Create a copy for each UID
                item_copy["UID"] = id
                item_copy["repo"] = repo
                item_copy["link"] = link
                UIDs.append(item_copy)
            continue
        else:
            item["UID"] = dataset
        item["repo"] = repo
        item["link"] = link

        UIDs.append(item)

# dataframe with the UIDs
UIDs_df = pd.DataFrame(UIDs)
print(UIDs_df)
"""