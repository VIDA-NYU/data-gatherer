{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:11.771743Z",
     "start_time": "2025-06-04T20:53:11.758340Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from data_gatherer.orchestrator import Orchestrator\n",
    "import os\n",
    "from lxml import etree\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import pandas as pd\n",
    "import dspy"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:13.164137Z",
     "start_time": "2025-06-04T20:53:11.776636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")  # google-bert/bert-base-uncased\n",
    "model = AutoModel.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")\n",
    "# model.eval()"
   ],
   "id": "8fc7bc9a0c6bcf8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:13.171010Z",
     "start_time": "2025-06-04T20:53:13.165985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embedding(text: str) -> torch.Tensor:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Mean pooling\n",
    "    last_hidden = outputs.last_hidden_state\n",
    "    mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden.size())\n",
    "    summed = (last_hidden * mask).sum(1)\n",
    "    count = mask.sum(1)\n",
    "    return (summed / count).squeeze()"
   ],
   "id": "4c0e6ea311142f8f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:13.184714Z",
     "start_time": "2025-06-04T20:53:13.173646Z"
    }
   },
   "cell_type": "code",
   "source": "data_gatherer = Orchestrator('config.json')",
   "id": "50b5c4f281f5d26e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "orchestrator.py - line 40 - INFO - Data_Gatherer Orchestrator initialized. Extraction step Model: gemini-2.0-flash\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:13.194706Z",
     "start_time": "2025-06-04T20:53:13.185912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find all the files in the html_xml_dir directory\n",
    "files = []\n",
    "for root, dirs, file_names in os.walk('../' + data_gatherer.config['html_xml_dir']):\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith('.xml'):\n",
    "            files.append(os.path.join(root, file_name))\n",
    "print(f\"Found {len(files)} XML files in {data_gatherer.config['html_xml_dir']}\")"
   ],
   "id": "618544f7c4ab014c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 XML files in html_xml_samples/\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:13.203153Z",
     "start_time": "2025-06-04T20:53:13.196744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_paragraphs_from_xml(xml_root) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extract paragraphs and their section context from an XML document.\n",
    "    \n",
    "    Args:\n",
    "        xml_root: lxml.etree.Element — parsed XML root.\n",
    "\n",
    "    Returns:\n",
    "        List of dicts with 'paragraph', 'section_title', and 'sec_type'.\n",
    "    \"\"\"\n",
    "    paragraphs = []\n",
    "\n",
    "    # Iterate over all section blocks\n",
    "    for sec in xml_root.findall(\".//sec\"):\n",
    "        sec_type = sec.get(\"sec-type\", \"unknown\")\n",
    "        title_elem = sec.find(\"title\")\n",
    "        section_title = title_elem.text.strip() if title_elem is not None and title_elem.text else \"No Title\"\n",
    "\n",
    "        for p in sec.findall(\".//p\"):\n",
    "            itertext = \" \".join(p.itertext()).strip()\n",
    "            para_text = etree.tostring(p, encoding=\"unicode\", method=\"xml\").strip()\n",
    "            if len(para_text) >= 5:  # avoid tiny/junk paragraphs\n",
    "                paragraphs.append({\n",
    "                    \"paragraph\": para_text,\n",
    "                    \"section_title\": section_title,\n",
    "                    \"sec_type\": sec_type,\n",
    "                    \"text\": itertext\n",
    "                })\n",
    "                #print(f\"Extracted paragraph: {paragraphs[-1]}\")\n",
    "\n",
    "    return paragraphs"
   ],
   "id": "e69937a2a1f97102",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:13.211403Z",
     "start_time": "2025-06-04T20:53:13.204685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_sections_from_xml(xml_root) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extract sections from an XML document.\n",
    "    \n",
    "    Args:\n",
    "        xml_root: lxml.etree.Element — parsed XML root.\n",
    "\n",
    "    Returns:\n",
    "        List of dicts with 'section_title' and 'sec_type'.\n",
    "    \"\"\"\n",
    "    sections = []\n",
    "\n",
    "    # Iterate over all section blocks\n",
    "    for sec in xml_root.findall(\".//sec\"):\n",
    "        sec_type = sec.get(\"sec-type\", \"unknown\")\n",
    "        title_elem = sec.find(\"title\")\n",
    "        section_title = title_elem.text.strip() if title_elem is not None and title_elem.text else \"No Title\"\n",
    "        \n",
    "        section_text_from_paragraphs = f'{section_title}\\n'\n",
    "        section_rawtxt_from_paragraphs = ''\n",
    "\n",
    "        for p in sec.findall(\".//p\"):\n",
    "            \n",
    "            itertext = \" \".join(p.itertext()).strip()\n",
    "            \n",
    "            if len(itertext) >= 5:\n",
    "                section_text_from_paragraphs += \"\\n\" + itertext + \"\\n\"\n",
    "            \n",
    "            para_text = etree.tostring(p, encoding=\"unicode\", method=\"xml\").strip()\n",
    "            \n",
    "            if len(para_text) >= 5:  # avoid tiny/junk paragraphs\n",
    "                section_rawtxt_from_paragraphs += \"\\n\" + para_text + \"\\n\"\n",
    "                \n",
    "        sections.append({\n",
    "                        \"raw_sec_txt\": section_rawtxt_from_paragraphs,\n",
    "                        \"section_title\": section_title,\n",
    "                        \"sec_type\": sec_type,\n",
    "                        \"sec_txt\": section_text_from_paragraphs\n",
    "                    })\n",
    "    return sections"
   ],
   "id": "2440629c6b7b2e3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:21.639079Z",
     "start_time": "2025-06-04T20:53:13.213300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = []\n",
    "for i,file in enumerate(files):\n",
    "    print(f\"Processing file {i+1}: {file}\")\n",
    "    with open(file, 'rb') as f:  # ✅ open in binary mode\n",
    "        xml_root = etree.fromstring(f.read())\n",
    "   \n",
    "    sections = extract_sections_from_xml(xml_root) # called at the beginning of LLM_Parser.parse_data\n",
    "    print(f\"Extracted {len(sections)} sections\")\n",
    "    \n",
    "    query = \"dataset reference\"\n",
    "    query_vec = get_embedding(query)\n",
    "    print(f\"Query '{query}' vectorized to shape {query_vec.shape}\")\n",
    "    \n",
    "    for j,sect in enumerate(sections):\n",
    "        sect_vec = get_embedding(sect['sec_txt'])\n",
    "        score = F.cosine_similarity(\n",
    "            F.normalize(query_vec.unsqueeze(0), dim=1), \n",
    "            F.normalize(sect_vec.unsqueeze(0), dim=1), \n",
    "            dim=1\n",
    "        ).item()\n",
    "        sect['embedding'] = sect_vec\n",
    "        sect['score'] = score\n",
    "        sect['source'] = file\n",
    "        print(f\"File_{i+1}-Section_{j} score: {score:.4f} for sec_txt: {sect['sec_txt'][:100]}...\")\n",
    "    \n",
    "    corpus.extend(sections)"
   ],
   "id": "f1376bf2b919bf5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1: ../html_xml_samples/PMC/Recurrent WNT pathway alterations are frequent in relapsed small cell lung cancer.xml\n",
      "Extracted 38 sections\n",
      "Query 'dataset reference' vectorized to shape torch.Size([768])\n",
      "File_1-Section_0 score: 0.8664 for sec_txt: Introduction\n",
      "\n",
      "Lung cancer is the leading cause of cancer-related death. Nearly 13% of patients with ...\n",
      "File_1-Section_1 score: 0.8727 for sec_txt: Results\n",
      "\n",
      "Consistent with previously published studies, the total tumor mutation burden (TMB) of sing...\n",
      "File_1-Section_2 score: 0.8728 for sec_txt: The mutational landscape of relapsed SCLCs\n",
      "\n",
      "Consistent with previously published studies, the total ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mQuery \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m vectorized to shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_vec.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m j,sect \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sections):\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     sect_vec = get_embedding(sect[\u001B[33m'\u001B[39m\u001B[33msec_txt\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     16\u001B[39m     score = F.cosine_similarity(\n\u001B[32m     17\u001B[39m         F.normalize(query_vec.unsqueeze(\u001B[32m0\u001B[39m), dim=\u001B[32m1\u001B[39m), \n\u001B[32m     18\u001B[39m         F.normalize(sect_vec.unsqueeze(\u001B[32m0\u001B[39m), dim=\u001B[32m1\u001B[39m), \n\u001B[32m     19\u001B[39m         dim=\u001B[32m1\u001B[39m\n\u001B[32m     20\u001B[39m     ).item()\n\u001B[32m     21\u001B[39m     sect[\u001B[33m'\u001B[39m\u001B[33membedding\u001B[39m\u001B[33m'\u001B[39m] = sect_vec\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mget_embedding\u001B[39m\u001B[34m(text)\u001B[39m\n\u001B[32m      2\u001B[39m inputs = tokenizer(text, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m, truncation=\u001B[38;5;28;01mTrue\u001B[39;00m, max_length=\u001B[32m512\u001B[39m)\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     outputs = model(**inputs)\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# Mean pooling\u001B[39;00m\n\u001B[32m      6\u001B[39m last_hidden = outputs.last_hidden_state\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001B[39m, in \u001B[36mBertModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1134\u001B[39m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[32m   1135\u001B[39m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[32m   1136\u001B[39m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[32m   1137\u001B[39m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[32m   1138\u001B[39m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[32m   1139\u001B[39m head_mask = \u001B[38;5;28mself\u001B[39m.get_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers)\n\u001B[32m-> \u001B[39m\u001B[32m1141\u001B[39m encoder_outputs = \u001B[38;5;28mself\u001B[39m.encoder(\n\u001B[32m   1142\u001B[39m     embedding_output,\n\u001B[32m   1143\u001B[39m     attention_mask=extended_attention_mask,\n\u001B[32m   1144\u001B[39m     head_mask=head_mask,\n\u001B[32m   1145\u001B[39m     encoder_hidden_states=encoder_hidden_states,\n\u001B[32m   1146\u001B[39m     encoder_attention_mask=encoder_extended_attention_mask,\n\u001B[32m   1147\u001B[39m     past_key_values=past_key_values,\n\u001B[32m   1148\u001B[39m     use_cache=use_cache,\n\u001B[32m   1149\u001B[39m     output_attentions=output_attentions,\n\u001B[32m   1150\u001B[39m     output_hidden_states=output_hidden_states,\n\u001B[32m   1151\u001B[39m     return_dict=return_dict,\n\u001B[32m   1152\u001B[39m )\n\u001B[32m   1153\u001B[39m sequence_output = encoder_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1154\u001B[39m pooled_output = \u001B[38;5;28mself\u001B[39m.pooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001B[39m, in \u001B[36mBertEncoder.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    683\u001B[39m     layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m    684\u001B[39m         layer_module.\u001B[34m__call__\u001B[39m,\n\u001B[32m    685\u001B[39m         hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    691\u001B[39m         output_attentions,\n\u001B[32m    692\u001B[39m     )\n\u001B[32m    693\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m694\u001B[39m     layer_outputs = layer_module(\n\u001B[32m    695\u001B[39m         hidden_states,\n\u001B[32m    696\u001B[39m         attention_mask,\n\u001B[32m    697\u001B[39m         layer_head_mask,\n\u001B[32m    698\u001B[39m         encoder_hidden_states,\n\u001B[32m    699\u001B[39m         encoder_attention_mask,\n\u001B[32m    700\u001B[39m         past_key_value,\n\u001B[32m    701\u001B[39m         output_attentions,\n\u001B[32m    702\u001B[39m     )\n\u001B[32m    704\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:584\u001B[39m, in \u001B[36mBertLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    572\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    573\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    574\u001B[39m     hidden_states: torch.Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    581\u001B[39m ) -> Tuple[torch.Tensor]:\n\u001B[32m    582\u001B[39m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[32m    583\u001B[39m     self_attn_past_key_value = past_key_value[:\u001B[32m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m584\u001B[39m     self_attention_outputs = \u001B[38;5;28mself\u001B[39m.attention(\n\u001B[32m    585\u001B[39m         hidden_states,\n\u001B[32m    586\u001B[39m         attention_mask,\n\u001B[32m    587\u001B[39m         head_mask,\n\u001B[32m    588\u001B[39m         output_attentions=output_attentions,\n\u001B[32m    589\u001B[39m         past_key_value=self_attn_past_key_value,\n\u001B[32m    590\u001B[39m     )\n\u001B[32m    591\u001B[39m     attention_output = self_attention_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    593\u001B[39m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:514\u001B[39m, in \u001B[36mBertAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    504\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    505\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    506\u001B[39m     hidden_states: torch.Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    512\u001B[39m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    513\u001B[39m ) -> Tuple[torch.Tensor]:\n\u001B[32m--> \u001B[39m\u001B[32m514\u001B[39m     self_outputs = \u001B[38;5;28mself\u001B[39m.self(\n\u001B[32m    515\u001B[39m         hidden_states,\n\u001B[32m    516\u001B[39m         attention_mask,\n\u001B[32m    517\u001B[39m         head_mask,\n\u001B[32m    518\u001B[39m         encoder_hidden_states,\n\u001B[32m    519\u001B[39m         encoder_attention_mask,\n\u001B[32m    520\u001B[39m         past_key_value,\n\u001B[32m    521\u001B[39m         output_attentions,\n\u001B[32m    522\u001B[39m     )\n\u001B[32m    523\u001B[39m     attention_output = \u001B[38;5;28mself\u001B[39m.output(self_outputs[\u001B[32m0\u001B[39m], hidden_states)\n\u001B[32m    524\u001B[39m     outputs = (attention_output,) + self_outputs[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:394\u001B[39m, in \u001B[36mBertSdpaSelfAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    382\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().forward(\n\u001B[32m    383\u001B[39m         hidden_states,\n\u001B[32m    384\u001B[39m         attention_mask,\n\u001B[32m   (...)\u001B[39m\u001B[32m    389\u001B[39m         output_attentions,\n\u001B[32m    390\u001B[39m     )\n\u001B[32m    392\u001B[39m bsz, tgt_len, _ = hidden_states.size()\n\u001B[32m--> \u001B[39m\u001B[32m394\u001B[39m query_layer = \u001B[38;5;28mself\u001B[39m.transpose_for_scores(\u001B[38;5;28mself\u001B[39m.query(hidden_states))\n\u001B[32m    396\u001B[39m \u001B[38;5;66;03m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001B[39;00m\n\u001B[32m    397\u001B[39m \u001B[38;5;66;03m# mask needs to be such that the encoder's padding tokens are not attended to.\u001B[39;00m\n\u001B[32m    398\u001B[39m is_cross_attention = encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/opt/miniconda3/envs/Summer24/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.linear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m.weight, \u001B[38;5;28mself\u001B[39m.bias)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:53:21.641503Z",
     "start_time": "2025-06-04T20:53:21.641366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def embedder(texts):\n",
    "    return embedder_model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "for i,file in enumerate(files):\n",
    "    print(f\"Processing file {i+1}: {file}\")\n",
    "    with open(file, 'rb') as f:  # ✅ open in binary mode\n",
    "        xml_root = etree.fromstring(f.read())\n",
    "   \n",
    "    sections = extract_sections_from_xml(xml_root) # called at the beginning of LLM_Parser.parse_data\n",
    "    print(f\"Extracted {len(sections)} sections\")\n",
    "    \n",
    "    if len(sections) == 0:\n",
    "        print(f\"No sections found in file {file}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    query = \"Data available with accession code ABC0123 in Repository XYZ\"\n",
    "    \n",
    "    texts = [section['sec_txt'] for section in sections]\n",
    "    \n",
    "    embedder_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L3-v2\")\n",
    "    \n",
    "    \n",
    "    retriever = dspy.retrievers.Embeddings(\n",
    "        corpus=texts,\n",
    "        embedder=embedder,\n",
    "        k=1  # number of results to return\n",
    "    )\n",
    "    \n",
    "    result = retriever(query)\n",
    "    \n",
    "    for p in result.passages:\n",
    "        #print(\"Retrieved:\", p)\n",
    "        \n",
    "        # check if the section is in the corpus\n",
    "        for section in sections:\n",
    "            if section['sec_txt'] == p:\n",
    "                print(\"Found in corpus!!\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Not found in corpus\")\n",
    "            print(\"Section text:\", p)"
   ],
   "id": "8be5a38574cd7a7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(corpus), len(corpus), corpus[0].keys(), corpus[0].values()",
   "id": "d424d1e3f74011b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for section in corpus:\n",
    "    # Convert the embedding tensor to a list for JSON serialization\n",
    "    section['embedding'] = section['embedding'].tolist() if isinstance(section['embedding'], torch.Tensor) else section['embedding']\n",
    "    # Convert the score to a float\n",
    "    section['score'] = float(section['score'])"
   ],
   "id": "d45d765cc18cba6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# write corpus to a file\n",
    "with open('pubmed_section_corpus_PubMedBERT-embeddings.json', 'w') as f:\n",
    "    json.dump(corpus, f, indent=2)"
   ],
   "id": "e4a20adf3aac6549",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# json to excel\n",
    "df = pd.DataFrame(corpus)\n",
    "df.to_excel('PubMedBERT_pubmed_paragraphs_corpus-embeddings.xlsx', index=False)"
   ],
   "id": "feddeb222c70b81",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
