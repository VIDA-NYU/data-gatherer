{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gatherer.data_gatherer import DataGatherer\n",
    "from data_gatherer.llm.response_schema import *\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "from lxml import etree\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a039d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_parquet(\"scripts/output/gold/dataset_citation_records_Table.parquet\")\n",
    "\n",
    "input_file = \"scripts/exp_input/REV.txt\"\n",
    "batch_file_path=f'scripts/tmp/batch_requests_openai_RTR-3_DataRef-REV.jsonl'\n",
    "\n",
    "model_name = \"gpt-4o-mini\" \n",
    "FDR = False\n",
    "semantic_retrieval = True\n",
    "brute_force_RegEx_ID_ptrs = True\n",
    "top_k = 3\n",
    "embeddings_retriever_model = None\n",
    "dedup = True\n",
    "prompt_name = \"GPT_FewShot\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01742ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list to a text file\n",
    "with open(input_file, 'r') as f:\n",
    "    pmcids = f.read().splitlines()\n",
    "\n",
    "print(\"Number of PMCIDs:\", len(pmcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGatherer(\n",
    "    llm_name=model_name, \n",
    "    log_level='WARNING', \n",
    "    process_entire_document=FDR, \n",
    "    driver_path=None, \n",
    "    save_to_cache=False, \n",
    "    load_from_cache=False,\n",
    "    embeds_cache_read=True,\n",
    "    embeds_cache_write=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('scripts/exp_input/Local_fulltext_pub_REV.parquet'):\n",
    "    publication_fulltext_df = pd.read_parquet('scripts/exp_input/Local_fulltext_pub_REV.parquet')\n",
    "    publication_fulltext = publication_fulltext_df.to_dict(orient='index')\n",
    "else:\n",
    "    publication_fulltext = dg.fetch_data(pmcids,write_df_to_path='scripts/exp_input/Local_fulltext_pub_REV.parquet')\n",
    "    publication_fulltext_df = pd.DataFrame.from_dict(publication_fulltext, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81352328",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_counts = {}\n",
    "for url, data in publication_fulltext.items():\n",
    "    if data and 'raw_data_format' in data:\n",
    "        fmt = data['raw_data_format']\n",
    "        if fmt not in format_counts:\n",
    "            format_counts[fmt] = {'count': 0, 'urls': []}\n",
    "        format_counts[fmt]['count'] += 1\n",
    "        format_counts[fmt]['urls'].append(url)\n",
    "            \n",
    "# Log format frequencies (counts only for readability)\n",
    "frequency_summary = {fmt: info['count'] for fmt, info in format_counts.items()}\n",
    "dg.logger.info(f\"Fetched {len(publication_fulltext)} Papers. Format frequencies: {frequency_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_requests, cnt, last_url_raw_data_format = [], 0, False\n",
    "\n",
    "for url_raw_data_format, vals in format_counts.items():\n",
    "    for url in vals['urls']:\n",
    "\n",
    "        msg_already_added = ''\n",
    "        \n",
    "        data = publication_fulltext[url]\n",
    "        dg.logger.info(f\"type of data: {type(data['fetched_data'])}\")\n",
    "\n",
    "        if isinstance(data['fetched_data'], str) and url_raw_data_format.upper() == 'XML':\n",
    "            dg.logger.info(\"string data is not supported input, need etree\")\n",
    "            data['fetched_data'] = etree.fromstring(data['fetched_data'].encode('utf-8'))\n",
    "\n",
    "        try:                        \n",
    "            if cnt != 0 and url_raw_data_format == last_url_raw_data_format:\n",
    "                dg.logger.info(f\"Reusing existing parser of name: {dg.parser.__class__.__name__}\")\n",
    "            else:\n",
    "                dg.logger.info(f\"Creating new parser for format: {url_raw_data_format}\")\n",
    "                dg.init_parser_by_input_type(url_raw_data_format, data['fetched_data'], embeddings_retriever_model)\n",
    "                        \n",
    "            # Generate unique custom_id\n",
    "            article_id = dg.url_to_page_id(url)\n",
    "            pmcid = dg.data_fetcher.url_to_pmcid(url)\n",
    "            timestamp = int(time.time() * 1000)\n",
    "            custom_id = f\"{dg.llm}_{article_id}_{timestamp}\"\n",
    "            custom_id = re.sub(r'[^a-zA-Z0-9_-]', '_', custom_id)[:64]\n",
    "\n",
    "            dg.logger.info(f'normalize input')\n",
    "                        \n",
    "            if dg.full_document_read:\n",
    "                if url_raw_data_format.upper() == 'XML':\n",
    "                    normalized_input = (dg.parser.normalize_XML(data['fetched_data']) \n",
    "                                        if hasattr(dg.parser, 'normalize_XML') \n",
    "                                        else data['fetched_data'])\n",
    "                elif url_raw_data_format.upper() == 'HTML':\n",
    "                    normalized_input = (dg.parser.normalize_HTML(data['fetched_data']) \n",
    "                                                if hasattr(dg.parser, 'normalize_HTML') \n",
    "                                                else data['fetched_data'])\n",
    "                elif url_raw_data_format.upper() == 'PDF':\n",
    "                    normalized_input = data['fetched_data']\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported raw data format: {url_raw_data_format}\")\n",
    "                        \n",
    "            else:\n",
    "                data_availability_obj = dg.parser.retrieve_relevant_content(\n",
    "                                data['fetched_data'],\n",
    "                                semantic_retrieval=semantic_retrieval,\n",
    "                                top_k=top_k,\n",
    "                                skip_rule_based_retrieved_elm=dedup,\n",
    "                                include_snippets_with_ID_patterns=brute_force_RegEx_ID_ptrs,\n",
    "                                article_id=dg.data_fetcher.url_to_pmcid(url),\n",
    "                                output_format='json'\n",
    "                            )\n",
    "                dg.logger.info(f\"type of data_availability_obj: {type(data_availability_obj)}\")\n",
    "                dg.logger.info(f\"length of data_availability_obj: {len(data_availability_obj)}\")\n",
    "                dg.logger.info(f\"data_availability_obj content: {data_availability_obj}\")\n",
    "\n",
    "                for idx, obj in enumerate(data_availability_obj):\n",
    "                    dg.logger.info(f\"Object type in data_availability_obj: {type(obj)}\")\n",
    "\n",
    "                    # Extract text and metadata from obj\n",
    "                    if isinstance(obj, dict) and 'text' in obj:\n",
    "                        normalized_input = obj['text']\n",
    "                        # Preserve all other attributes in metadata (excluding 'text')\n",
    "                        obj_metadata = {k: v for k, v in obj.items() if k != 'text'}\n",
    "                    elif isinstance(obj, str):\n",
    "                        normalized_input = obj\n",
    "                        obj_metadata = {}\n",
    "                    else:\n",
    "                        dg.logger.warning(f\"Unsupported object type in data_availability_obj: {type(obj)}\")\n",
    "                        continue\n",
    "\n",
    "                    # Render prompt using the correct parser\n",
    "                    static_prompt = dg.parser.prompt_manager.load_prompt(prompt_name)\n",
    "                    messages = dg.parser.prompt_manager.render_prompt(\n",
    "                                    static_prompt,\n",
    "                                    entire_doc=dg.full_document_read,\n",
    "                                    content=normalized_input,\n",
    "                                    repos=', '.join(dg.parser.repo_names) if hasattr(dg.parser, 'repo_names') else '',\n",
    "                                    url=url\n",
    "                                )\n",
    "                    \n",
    "                    # Create unique custom_id for each snippet\n",
    "                    snippet_custom_id = f\"{custom_id}_snippet_{idx}\"\n",
    "                                \n",
    "                    # Create batch request for LLMClient\n",
    "                    batch_request = {\n",
    "                                    'custom_id': snippet_custom_id,\n",
    "                                    'messages': messages,\n",
    "                                    'metadata': {\n",
    "                                        'url': url,\n",
    "                                        'article_id': article_id,\n",
    "                                        'raw_data_format': url_raw_data_format,\n",
    "                                        'snippet_index': idx,\n",
    "                                        **obj_metadata  # Preserve all attributes from obj\n",
    "                                    }\n",
    "                                }\n",
    "                                \n",
    "                    batch_requests.append(batch_request)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            dg.logger.error(f\"Error preparing request for {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        last_url_raw_data_format = url_raw_data_format\n",
    "        cnt+=1\n",
    "            \n",
    "dg.logger.info(f\"Prepared {len(batch_requests)} batch requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc02dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_result = dg.parser.llm_client._handle_batch_mode(\n",
    "                batch_requests=batch_requests,\n",
    "                batch_file_path=batch_file_path,\n",
    "                temperature=0,\n",
    "                response_format=dataset_response_schema_gpt,\n",
    "                api_provider='openai'\n",
    "                )\n",
    "            \n",
    "result = {\n",
    "    'batch_file_created': batch_result,\n",
    "    'fetched_data_count': len(publication_fulltext),\n",
    "    'processed_requests': len(batch_requests),\n",
    "    'api_provider': 'openai',\n",
    "    'model': dg.llm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da50d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_filepath = batch_file_path\n",
    "prompts_load = []\n",
    "with open(prompts_filepath, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            prompts_load.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a279865",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_avg, bad_input, empty_prompt = 0, 0, []\n",
    "n_dfs = len(prompts_load)\n",
    "\n",
    "for prompt in prompts_load:\n",
    "    pmc_id = dg.data_fetcher.url_to_pmcid(prompt['custom_id'])\n",
    "    gt = df_gt[df_gt['pmcid'] == pmc_id]\n",
    "    datasets_gt = gt['identifier'].values.tolist()\n",
    "    #print(f\"datasets: {datasets_gt}\")\n",
    "    body_msg = [item['content'] for item in prompt['body']['input']]\n",
    "    #print (f\"prompt: {body_msg}\")\n",
    "    input_cont_str = \"\\n\".join(body_msg)\n",
    "\n",
    "    datasets_found, datasets_tot = 0, len(datasets_gt)\n",
    "    contains_one = False\n",
    "    for dataset in datasets_gt:\n",
    "        if dataset.lower() in input_cont_str.lower():\n",
    "            datasets_found += 1\n",
    "            contains_one = True\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Missing dataset {dataset} in prompt {prompt['custom_id']} for pmcid {pmc_id}\")\n",
    "    if not contains_one:\n",
    "        bad_input += 1\n",
    "        empty_prompt.append(prompt['custom_id'])\n",
    "    found_i = datasets_found / datasets_tot if datasets_tot > 0 else 1.0\n",
    "    found_avg += found_i/n_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_avg, bad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f47360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chunking and submission - NO monitoring or result combination\n",
    "result = dg.split_jsonl_and_submit(\n",
    "    batch_file_path=batch_file_path,\n",
    "    max_file_size_mb=200.0,\n",
    "    api_provider='openai',\n",
    "    wait_between_submissions=30,\n",
    "    batch_description=f\"Training Dataset Creation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = 'batch_691974ec3118819092006c7b16f0f9f6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eef3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dg.parser:\n",
    "    dg.parser = XMLParser(open_data_repos_ontology=\"open_bio_data_repos.json\", logger=dg.logger,\n",
    "    llm_name=dg.llm)\n",
    "\n",
    "res = dg.parser.llm_client.download_batch_results(\n",
    "    batch_id=batch_train,\n",
    "    output_file_path='scripts/tmp/Train_results.jsonl',\n",
    "    api_provider='openai'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa102e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split pmcids into train / val / test using sklearn (70/15/15 by default)\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "random_state = 42\n",
    "\n",
    "# first split off the test set\n",
    "train_val, test_ids = sklearn.model_selection.train_test_split(\n",
    "    pmcids, test_size=test_size, random_state=random_state, shuffle=True\n",
    ")\n",
    "\n",
    "# compute relative validation size w.r.t. the remaining data and split train/val\n",
    "val_relative = val_size / (1.0 - test_size)\n",
    "train_ids, val_ids = sklearn.model_selection.train_test_split(\n",
    "    train_val, test_size=val_relative, random_state=random_state, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Total: {len(pmcids)}  -> train: {len(train_ids)}, val: {len(val_ids)}, test: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed271994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07152885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc86b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b74a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
