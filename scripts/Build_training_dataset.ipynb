{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a039d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gatherer.data_gatherer import DataGatherer\n",
    "from data_gatherer.llm.response_schema import *\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "from lxml import etree\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01742ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_parquet(\"scripts/output/gold/dataset_citation_records_Table.parquet\")\n",
    "\n",
    "input_file = \"scripts/exp_input/REV.txt\"\n",
    "batch_file_path=f'scripts/tmp/train_data_openai_RTR-3_DataRef-REV.jsonl'\n",
    "output_batch_file = 'scripts/tmp/Train_results.jsonl'\n",
    "\n",
    "excel_output_path = 'scripts/tmp/training_dataset_validation.xlsx'\n",
    "\n",
    "model_name = \"gpt-4o-mini\" \n",
    "FDR = False\n",
    "semantic_retrieval = True\n",
    "brute_force_RegEx_ID_ptrs = True\n",
    "\n",
    "top_k = 3\n",
    "embeddings_retriever_model = None\n",
    "dedup = True\n",
    "prompt_name = \"GPT_FewShot\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list to a text file\n",
    "with open(input_file, 'r') as f:\n",
    "    pmcids = f.read().splitlines()\n",
    "\n",
    "print(\"Number of PMCIDs:\", len(pmcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGatherer(\n",
    "    llm_name=model_name, \n",
    "    log_level='WARNING', \n",
    "    process_entire_document=FDR, \n",
    "    driver_path=None, \n",
    "    save_to_cache=False, \n",
    "    load_from_cache=False,\n",
    "    embeds_cache_read=True,\n",
    "    embeds_cache_write=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81352328",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('scripts/exp_input/Local_fulltext_pub_REV.parquet'):\n",
    "    publication_fulltext_df = pd.read_parquet('scripts/exp_input/Local_fulltext_pub_REV.parquet')\n",
    "    publication_fulltext = publication_fulltext_df.to_dict(orient='index')\n",
    "else:\n",
    "    publication_fulltext = dg.fetch_data(pmcids,write_df_to_path='scripts/exp_input/Local_fulltext_pub_REV.parquet')\n",
    "    publication_fulltext_df = pd.DataFrame.from_dict(publication_fulltext, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81352328",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_counts = {}\n",
    "for url, data in publication_fulltext.items():\n",
    "    if url not in pmcids:\n",
    "        continue\n",
    "    if data and 'raw_data_format' in data:\n",
    "        fmt = data['raw_data_format']\n",
    "        if fmt not in format_counts:\n",
    "            format_counts[fmt] = {'count': 0, 'urls': []}\n",
    "        format_counts[fmt]['count'] += 1\n",
    "        format_counts[fmt]['urls'].append(url)\n",
    "            \n",
    "# Log format frequencies (counts only for readability)\n",
    "frequency_summary = {fmt: info['count'] for fmt, info in format_counts.items()}\n",
    "dg.logger.info(f\"Fetched {len(publication_fulltext)} Papers. Format frequencies: {frequency_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_requests, cnt, last_url_raw_data_format = [], 0, False\n",
    "\n",
    "for url_raw_data_format, vals in format_counts.items():\n",
    "    for url in vals['urls']:\n",
    "\n",
    "        msg_already_added = ''\n",
    "        \n",
    "        data = publication_fulltext[url]\n",
    "        dg.logger.info(f\"type of data: {type(data['fetched_data'])}\")\n",
    "\n",
    "        if isinstance(data['fetched_data'], str) and url_raw_data_format.upper() == 'XML':\n",
    "            dg.logger.info(\"string data is not supported input, need etree\")\n",
    "            data['fetched_data'] = etree.fromstring(data['fetched_data'].encode('utf-8'))\n",
    "\n",
    "        try:                        \n",
    "            if cnt != 0 and url_raw_data_format == last_url_raw_data_format:\n",
    "                dg.logger.info(f\"Reusing existing parser of name: {dg.parser.__class__.__name__}\")\n",
    "            else:\n",
    "                dg.logger.info(f\"Creating new parser for format: {url_raw_data_format}\")\n",
    "                dg.init_parser_by_input_type(url_raw_data_format, data['fetched_data'], embeddings_retriever_model)\n",
    "                        \n",
    "            # Generate unique custom_id\n",
    "            article_id = dg.url_to_page_id(url)\n",
    "            pmcid = dg.data_fetcher.url_to_pmcid(url)\n",
    "            timestamp = int(time.time() * 1000)\n",
    "            custom_id = f\"{dg.llm}_{article_id}_{timestamp}\"\n",
    "            custom_id = re.sub(r'[^a-zA-Z0-9_-]', '_', custom_id)[:64]\n",
    "                        \n",
    "            if dg.full_document_read:\n",
    "                dg.logger.info(f'normalize input')\n",
    "                if url_raw_data_format.upper() == 'XML':\n",
    "                    normalized_input = (dg.parser.normalize_XML(data['fetched_data']) \n",
    "                                        if hasattr(dg.parser, 'normalize_XML') \n",
    "                                        else data['fetched_data'])\n",
    "                elif url_raw_data_format.upper() == 'HTML':\n",
    "                    normalized_input = (dg.parser.normalize_HTML(data['fetched_data']) \n",
    "                                                if hasattr(dg.parser, 'normalize_HTML') \n",
    "                                                else data['fetched_data'])\n",
    "                elif url_raw_data_format.upper() == 'PDF':\n",
    "                    normalized_input = data['fetched_data']\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported raw data format: {url_raw_data_format}\")\n",
    "                        \n",
    "            else:\n",
    "                dg.logger.info(f'relevant section retrieval')\n",
    "                data_availability_obj = dg.parser.retrieve_relevant_content(\n",
    "                                data['fetched_data'],\n",
    "                                semantic_retrieval=semantic_retrieval,\n",
    "                                top_k=top_k,\n",
    "                                skip_rule_based_retrieved_elm=dedup,\n",
    "                                include_snippets_with_ID_patterns=brute_force_RegEx_ID_ptrs,\n",
    "                                article_id=dg.data_fetcher.url_to_pmcid(url),\n",
    "                                output_format='json'\n",
    "                            )\n",
    "                dg.logger.info(f\"type of data_availability_obj: {type(data_availability_obj)}\")\n",
    "                dg.logger.info(f\"length of data_availability_obj: {len(data_availability_obj)}\")\n",
    "                dg.logger.info(f\"data_availability_obj content: {data_availability_obj}\")\n",
    "\n",
    "                for idx, obj in enumerate(data_availability_obj):\n",
    "                    dg.logger.info(f\"Object type in data_availability_obj: {type(obj)}\")\n",
    "\n",
    "                    # Extract text and metadata from obj\n",
    "                    if isinstance(obj, dict) and 'text' in obj:\n",
    "                        normalized_input = obj['text']\n",
    "                        # Preserve all other attributes in metadata (excluding 'text')\n",
    "                        obj_metadata = {k: v for k, v in obj.items() if k != 'text'}\n",
    "                    elif isinstance(obj, str):\n",
    "                        normalized_input = obj\n",
    "                        obj_metadata = {}\n",
    "                    else:\n",
    "                        dg.logger.warning(f\"Unsupported object type in data_availability_obj: {type(obj)}\")\n",
    "                        continue\n",
    "\n",
    "                    # Render prompt using the correct parser\n",
    "                    static_prompt = dg.parser.prompt_manager.load_prompt(prompt_name)\n",
    "                    messages = dg.parser.prompt_manager.render_prompt(\n",
    "                                    static_prompt,\n",
    "                                    entire_doc=dg.full_document_read,\n",
    "                                    content=normalized_input,\n",
    "                                    repos=', '.join(dg.parser.repo_names) if hasattr(dg.parser, 'repo_names') else '',\n",
    "                                    url=url\n",
    "                                )\n",
    "                    \n",
    "                    # Create unique custom_id for each snippet\n",
    "                    snippet_custom_id = f\"{custom_id}_snippet_{idx}\"\n",
    "                                \n",
    "                    # Create batch request for LLMClient\n",
    "                    batch_request = {\n",
    "                                    'custom_id': snippet_custom_id,\n",
    "                                    'messages': messages,\n",
    "                                    'metadata': {\n",
    "                                        'url': url,\n",
    "                                        'article_id': article_id,\n",
    "                                        'raw_data_format': url_raw_data_format,\n",
    "                                        'snippet_index': idx,\n",
    "                                        **obj_metadata  # Preserve all attributes from obj\n",
    "                                    }\n",
    "                                }\n",
    "                                \n",
    "                    batch_requests.append(batch_request)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            dg.logger.error(f\"Error preparing request for {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        last_url_raw_data_format = url_raw_data_format\n",
    "        cnt+=1\n",
    "            \n",
    "dg.logger.info(f\"Prepared {len(batch_requests)} batch requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc02dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_result = dg.parser.llm_client._handle_batch_mode(\n",
    "                batch_requests=batch_requests,\n",
    "                batch_file_path=batch_file_path,\n",
    "                temperature=0,\n",
    "                response_format=dataset_response_schema_gpt,\n",
    "                api_provider='openai'\n",
    "                )\n",
    "            \n",
    "result = {\n",
    "    'batch_file_created': batch_result,\n",
    "    'fetched_data_count': len(publication_fulltext),\n",
    "    'processed_requests': len(batch_requests),\n",
    "    'api_provider': 'openai',\n",
    "    'model': dg.llm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da50d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_filepath = batch_file_path\n",
    "prompts_load = []\n",
    "with open(prompts_filepath, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            prompts_load.append(json.loads(line))\n",
    "len(prompts_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a279865",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_avg, bad_input, empty_prompt = 0, 0, []\n",
    "n_dfs = len(prompts_load)\n",
    "\n",
    "for prompt in prompts_load:\n",
    "    pmc_id = dg.data_fetcher.url_to_pmcid(prompt['custom_id'])\n",
    "    gt = df_gt[df_gt['pmcid'] == pmc_id]\n",
    "    datasets_gt = gt['identifier'].values.tolist()\n",
    "    #print(f\"datasets: {datasets_gt}\")\n",
    "    body_msg = [item['content'] for item in prompt['body']['input']]\n",
    "    #print (f\"prompt: {body_msg}\")\n",
    "    input_cont_str = \"\\n\".join(body_msg)\n",
    "\n",
    "    datasets_found, datasets_tot = 0, len(datasets_gt)\n",
    "    contains_one = False\n",
    "    for dataset in datasets_gt:\n",
    "        if dataset.lower() in input_cont_str.lower():\n",
    "            datasets_found += 1\n",
    "            contains_one = True\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Missing dataset {dataset} in prompt {prompt['custom_id']} for pmcid {pmc_id}\")\n",
    "    if not contains_one:\n",
    "        bad_input += 1\n",
    "        empty_prompt.append(prompt['custom_id'])\n",
    "    found_i = datasets_found / datasets_tot if datasets_tot > 0 else 1.0\n",
    "    found_avg += found_i/n_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_avg, bad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f47360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chunking and submission - NO monitoring or result combination\n",
    "result = dg.split_jsonl_and_submit(\n",
    "    batch_file_path=batch_file_path,\n",
    "    max_file_size_mb=200.0,\n",
    "    api_provider='openai',\n",
    "    wait_between_submissions=30,\n",
    "    batch_description=f\"Training Dataset Creation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = 'batch_691bf0fcc7d081909d396c54e2082ced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eef3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dg.parser:\n",
    "    dg.init_parser_by_input_type('XML')\n",
    "\n",
    "res = dg.parser.llm_client.download_batch_results(\n",
    "    batch_id=batch_train,\n",
    "    output_file_path=output_batch_file,\n",
    "    api_provider='openai'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_batch_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(f\"Number of lines in combined file: {len(lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_file = 'scripts/output/semantic_search/Train_results.csv'\n",
    "ret_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dg.parser:\n",
    "    dg.init_parser_by_input_type('XML')\n",
    "\n",
    "res_df = dg.from_batch_resp_file_to_df(output_batch_file, output_file_path=ret_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df26db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(ret_file)\n",
    "len(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcids_ret = set([re.sub('(https://www.ncbi.nlm.nih.gov/pmc/articles/.*)/','\\\\1',item).lower() for item in res_df['source_url'].to_list()])\n",
    "pmcids = set([idx.lower() for idx in pmcids])\n",
    "missing_urls = list(pmcids - pmcids_ret)\n",
    "len(missing_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets_append = dg.process_articles(\n",
    "    missing_urls,\n",
    "    prompt_name=\"GPT_FewShot\",\n",
    "    full_document_read=FDR,\n",
    "    top_k = top_k,\n",
    "    semantic_retrieval=semantic_retrieval,\n",
    "    response_format=dataset_response_schema_gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bece05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_datasets_append), type(new_datasets_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# union dataframes\n",
    "for pmc_link in new_datasets_append.keys():\n",
    "    final_df = pd.concat([res_df, new_datasets_append[pmc_link]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(ret_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(ret_file)\n",
    "res_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961fe8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8252538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict creation\n",
    "train_dict = {}\n",
    "\n",
    "# Load prompts from the request file\n",
    "prompts_file = batch_file_path\n",
    "prompts_data = {}\n",
    "\n",
    "with open(prompts_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            prompt = json.loads(line)\n",
    "            custom_id = prompt['custom_id']\n",
    "            \n",
    "            # Extract content values from body.input array\n",
    "            input_messages = prompt['body']['input']\n",
    "            content_values = [msg['content'] for msg in input_messages if 'content' in msg]\n",
    "            just_context = content_values[1][1016:]\n",
    "            \n",
    "            # Store in prompts_data\n",
    "            prompts_data[custom_id] = {\n",
    "                'input_content': just_context,\n",
    "                'metadata': prompt.get('metadata', {})\n",
    "            }\n",
    "\n",
    "#print(f\"Loaded {len(prompts_data)} prompts from request file\")\n",
    "\n",
    "# Load results from the results file\n",
    "results_file = output_batch_file\n",
    "results_data = {}\n",
    "\n",
    "with open(results_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            result = json.loads(line)\n",
    "            custom_id = result['custom_id']\n",
    "            \n",
    "            # Extract output.text from response\n",
    "            output_text = None\n",
    "            if 'response' in result and 'body' in result['response']:\n",
    "                body = result['response']['body']\n",
    "                # Navigate: body -> output[0] -> content[0] -> text\n",
    "                if 'output' in body and len(body['output']) > 0:\n",
    "                    output_item = body['output'][0]\n",
    "                    if 'content' in output_item and len(output_item['content']) > 0:\n",
    "                        content_item = output_item['content'][0]\n",
    "                        if 'text' in content_item:\n",
    "                            output_text = content_item['text']\n",
    "            \n",
    "            results_data[custom_id] = {\n",
    "                'output_text': output_text\n",
    "            }\n",
    "\n",
    "#print(f\"Loaded {len(results_data)} results from results file\")\n",
    "\n",
    "# Combine prompts and results into train_dict\n",
    "for custom_id in prompts_data.keys():\n",
    "    if custom_id in results_data:\n",
    "        train_dict[custom_id] = {\n",
    "            'custom_id': custom_id,\n",
    "            'input_content': prompts_data[custom_id]['input_content'],\n",
    "            'output_text': results_data[custom_id]['output_text'],\n",
    "            'metadata': prompts_data[custom_id]['metadata']\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Warning: No result found for custom_id: {custom_id}\")\n",
    "\n",
    "print(f\"\\nCreated train_dict with {len(train_dict)} entries\")\n",
    "print(f\"Missing results: {len(prompts_data) - len(train_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941bfe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_n = 0\n",
    "for custom_id, entry in train_dict.items():\n",
    "    print(custom_id)\n",
    "    print(entry['metadata'])\n",
    "    print(entry['input_content'])\n",
    "    print(entry['output_text'])\n",
    "    iter_n += 1\n",
    "    if iter_n==3:\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523b04c",
   "metadata": {},
   "source": [
    "## Dataset Validation\n",
    "Convert train_dict to DataFrame for validation and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_dict to DataFrame for validation\n",
    "validation_records = []\n",
    "\n",
    "for custom_id, entry in train_dict.items():\n",
    "    # Join input content into a single string for readability\n",
    "    input_text = \"\\n---\\n\".join(entry['input_content']) if isinstance(entry['input_content'], list) else str(entry['input_content'])\n",
    "    \n",
    "    record = {\n",
    "        'custom_id': entry['custom_id'],\n",
    "        'url': entry['metadata'].get('url', ''),\n",
    "        'article_id': entry['metadata'].get('article_id', ''),\n",
    "        'raw_data_format': entry['metadata'].get('raw_data_format', ''),\n",
    "        'snippet_index': entry['metadata'].get('snippet_index', ''),\n",
    "        'section_title': entry['metadata'].get('section_title', ''),\n",
    "        'sec_type': entry['metadata'].get('sec_type', ''),\n",
    "        'L2_distance': entry['metadata'].get('L2_distance', ''),\n",
    "        'input_text': input_text,\n",
    "        'output_text': entry['output_text'],\n",
    "        'validated': '',  # Empty column for manual validation\n",
    "        'notes': ''  # Empty column for notes\n",
    "    }\n",
    "    validation_records.append(record)\n",
    "\n",
    "validation_df = pd.DataFrame(validation_records)\n",
    "print(f\"Created validation DataFrame with {len(validation_df)} rows\")\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel for validation (recommended - preserves formatting and allows filtering)\n",
    "validation_df.to_excel(excel_output_path, index=False, engine='openpyxl')\n",
    "print(f\"Exported to Excel: {excel_output_path}\")\n",
    "\n",
    "print(\"\\nYou can now:\")\n",
    "print(\"1. Open the Excel file to validate with filtering, sorting, and cell-by-cell editing\")\n",
    "print(\"2. Open the CSV file in any spreadsheet application\")\n",
    "print(\"3. Use the DataFrame below for in-notebook validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddf733",
   "metadata": {},
   "source": [
    "## Smart Duplicate Detection & Validation\n",
    "\n",
    "This section provides an intelligent duplicate detection system that:\n",
    "1. Identifies rows with identical `output_text` values\n",
    "2. Compares `input_text` using word frequency analysis\n",
    "3. Shows differences and prompts for manual validation\n",
    "4. Helps you efficiently curate your training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88849f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def count_word_frequencies(text):\n",
    "    \"\"\"Count word frequencies in text, case-insensitive.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return Counter()\n",
    "    # Simple word tokenization: split by whitespace and remove punctuation\n",
    "    words = str(text).lower().split()\n",
    "    # Remove common punctuation\n",
    "    cleaned_words = [''.join(c for c in word if c.isalnum() or c in '-_') for word in words]\n",
    "    cleaned_words = [w for w in cleaned_words if w]  # Remove empty strings\n",
    "    return Counter(cleaned_words)\n",
    "\n",
    "def compare_word_frequencies(freq1, freq2):\n",
    "    \"\"\"\n",
    "    Compare two word frequency counters and return differences.\n",
    "    Returns dict with words that have different frequencies.\n",
    "    \"\"\"\n",
    "    all_words = set(freq1.keys()) | set(freq2.keys())\n",
    "    differences = {}\n",
    "    \n",
    "    for word in all_words:\n",
    "        count1 = freq1.get(word, 0)\n",
    "        count2 = freq2.get(word, 0)\n",
    "        if count1 != count2:\n",
    "            differences[word] = {'current': count1, 'previous': count2}\n",
    "    \n",
    "    return differences\n",
    "\n",
    "def format_comparison_html(current_row, past_row, word_diffs, idx_current, idx_past):\n",
    "    \"\"\"\n",
    "    Create an HTML formatted comparison between two rows.\n",
    "    \"\"\"\n",
    "    html = f\"\"\"\n",
    "    <div style=\"font-family: monospace; border: 2px solid #333; padding: 20px; margin: 10px 0; background: #f9f9f9;\">\n",
    "        <h3 style=\"color: #d63031;\">üîç Potential Duplicate Detected</h3>\n",
    "        <hr>\n",
    "        \n",
    "        <h4 style=\"color: #0984e3;\">Current Row (Index: {idx_current})</h4>\n",
    "        <table style=\"width: 100%; border-collapse: collapse; margin: 10px 0;\">\n",
    "            <tr style=\"background: #dfe6e9;\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold; width: 150px;\">Custom ID</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{current_row['custom_id']}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">URL</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{current_row['url']}</td>\n",
    "            </tr>\n",
    "            <tr style=\"background: #dfe6e9;\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">Article ID</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{current_row['article_id']}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">Section</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{current_row['section_title']} ({current_row['sec_type']})</td>\n",
    "            </tr>\n",
    "            <tr style=\"background: #dfe6e9;\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">L2 Distance</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{current_row['L2_distance']}</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        \n",
    "        <h4 style=\"color: #6c5ce7;\">Previous Row (Index: {idx_past})</h4>\n",
    "        <table style=\"width: 100%; border-collapse: collapse; margin: 10px 0;\">\n",
    "            <tr style=\"background: #dfe6e9;\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold; width: 150px;\">Custom ID</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{past_row['custom_id']}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">URL</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{past_row['url']}</td>\n",
    "            </tr>\n",
    "            <tr style=\"background: #dfe6e9;\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">Article ID</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{past_row['article_id']}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">Section</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{past_row['section_title']} ({past_row['sec_type']})</td>\n",
    "            </tr>\n",
    "            <tr style=\"background: #dfe6e9;\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; font-weight: bold;\">L2 Distance</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\">{past_row['L2_distance']}</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        \n",
    "        <hr>\n",
    "        <h4 style=\"color: #e17055;\">üìä Word Frequency Differences in Input Text</h4>\n",
    "        <p style=\"color: #636e72;\">Words appearing different number of times between current and previous input texts:</p>\n",
    "        <table style=\"width: 100%; border-collapse: collapse; margin: 10px 0;\">\n",
    "            <tr style=\"background: #2d3436; color: white;\">\n",
    "                <th style=\"padding: 8px; border: 1px solid #000;\">Word</th>\n",
    "                <th style=\"padding: 8px; border: 1px solid #000;\">Current Count</th>\n",
    "                <th style=\"padding: 8px; border: 1px solid #000;\">Previous Count</th>\n",
    "                <th style=\"padding: 8px; border: 1px solid #000;\">Difference</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort by absolute difference\n",
    "    sorted_diffs = sorted(word_diffs.items(), \n",
    "                          key=lambda x: abs(x[1]['current'] - x[1]['previous']), \n",
    "                          reverse=True)\n",
    "    \n",
    "    for i, (word, counts) in enumerate(sorted_diffs[:50]):  # Show top 50 differences\n",
    "        bg_color = \"#dfe6e9\" if i % 2 == 0 else \"#ffffff\"\n",
    "        diff = counts['current'] - counts['previous']\n",
    "        diff_color = \"#00b894\" if diff > 0 else \"#d63031\"\n",
    "        html += f\"\"\"\n",
    "            <tr style=\"background: {bg_color};\">\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3;\"><code>{word}</code></td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; text-align: center;\">{counts['current']}</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; text-align: center;\">{counts['previous']}</td>\n",
    "                <td style=\"padding: 8px; border: 1px solid #b2bec3; text-align: center; color: {diff_color}; font-weight: bold;\">{diff:+d}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    if len(sorted_diffs) > 50:\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td colspan=\"4\" style=\"padding: 8px; text-align: center; font-style: italic; color: #636e72;\">\n",
    "                    ... and {len(sorted_diffs) - 50} more word differences\n",
    "                </td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "        </table>\n",
    "        \n",
    "        <hr>\n",
    "        <h4 style=\"color: #00b894;\">üìÑ Input Text Comparison</h4>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Show first 500 chars of each input text\n",
    "    current_input = str(current_row['input_text'])[:500]\n",
    "    past_input = str(past_row['input_text'])[:500]\n",
    "    \n",
    "    html += f\"\"\"\n",
    "        <div style=\"margin: 10px 0;\">\n",
    "            <p style=\"font-weight: bold; color: #0984e3;\">Current Input Text (first 500 chars):</p>\n",
    "            <pre style=\"background: #ecf0f1; padding: 10px; border-left: 4px solid #0984e3; overflow-x: auto;\">{current_input}...</pre>\n",
    "        </div>\n",
    "        <div style=\"margin: 10px 0;\">\n",
    "            <p style=\"font-weight: bold; color: #6c5ce7;\">Previous Input Text (first 500 chars):</p>\n",
    "            <pre style=\"background: #ecf0f1; padding: 10px; border-left: 4px solid #6c5ce7; overflow-x: auto;\">{past_input}...</pre>\n",
    "        </div>\n",
    "        \n",
    "        <hr>\n",
    "        <h4 style=\"color: #fdcb6e;\">üéØ Output Text (Identical)</h4>\n",
    "        <pre style=\"background: #fffbea; padding: 10px; border-left: 4px solid #fdcb6e; overflow-x: auto;\">{current_row['output_text']}</pre>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset\n",
    "validation_df = pd.read_excel(excel_output_path)\n",
    "print(f\"Loaded {len(validation_df)} rows from {excel_output_path}\")\n",
    "print(f\"Columns: {validation_df.columns.tolist()}\")\n",
    "\n",
    "# Initialize validation column if it doesn't exist\n",
    "if 'validated' not in validation_df.columns:\n",
    "    validation_df['validated'] = None\n",
    "if 'is_duplicate' not in validation_df.columns:\n",
    "    validation_df['is_duplicate'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aed3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build duplicate detection index with smart filtering\n",
    "output_text_index = {}  # Maps output_text -> list of row indices\n",
    "duplicate_pairs = []  # List of (current_idx, past_idx) tuples to review\n",
    "\n",
    "print(\"üîç Building duplicate detection index...\")\n",
    "\n",
    "# First, identify \"no dataset\" patterns\n",
    "no_dataset_patterns = ['n/a', 'not applicable', 'no dataset', 'none']\n",
    "\n",
    "def is_no_dataset_response(output_text):\n",
    "    \"\"\"Check if output indicates no dataset found.\"\"\"\n",
    "    if pd.isna(output_text):\n",
    "        return True\n",
    "    text_lower = str(output_text).lower()\n",
    "    # Check if it's a JSON with n/a values\n",
    "    if 'dataset_identifier' in text_lower and '\"n/a\"' in text_lower:\n",
    "        return True\n",
    "    # Check for other no-dataset indicators\n",
    "    return any(pattern in text_lower for pattern in no_dataset_patterns)\n",
    "\n",
    "no_dataset_rows = []\n",
    "real_duplicate_pairs = []\n",
    "\n",
    "for idx, row in validation_df.iterrows():\n",
    "    output_text = row['output_text']\n",
    "    \n",
    "    # Separate handling for \"no dataset\" responses\n",
    "    if is_no_dataset_response(output_text):\n",
    "        no_dataset_rows.append(idx)\n",
    "        continue\n",
    "    \n",
    "    # For real dataset responses, track duplicates\n",
    "    if output_text in output_text_index:\n",
    "        # Found a duplicate output_text!\n",
    "        # Only compare with the FIRST occurrence to avoid explosion\n",
    "        # (if you want all pairs, we can add that as an option)\n",
    "        first_idx = output_text_index[output_text][0]\n",
    "        real_duplicate_pairs.append((idx, first_idx))\n",
    "        \n",
    "        # Add current index to the list\n",
    "        output_text_index[output_text].append(idx)\n",
    "    else:\n",
    "        # First occurrence\n",
    "        output_text_index[output_text] = [idx]\n",
    "\n",
    "# Summary\n",
    "duplicate_pairs = real_duplicate_pairs\n",
    "no_dataset_count = len(no_dataset_rows)\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis complete!\")\n",
    "print(f\"üìä No-dataset responses: {no_dataset_count} rows ({no_dataset_count/len(validation_df)*100:.1f}%)\")\n",
    "print(f\"üìä Real dataset responses: {len(validation_df) - no_dataset_count} rows\")\n",
    "print(f\"\\nüîç Duplicate detection (real datasets only):\")\n",
    "print(f\"   Unique output_text values: {len(output_text_index)}\")\n",
    "print(f\"   Duplicate pairs to review: {len(duplicate_pairs)}\")\n",
    "print(f\"   Total rows with duplicate output_text: {sum(1 for v in output_text_index.values() if len(v) > 1)}\")\n",
    "\n",
    "print(f\"\\nüí° Tip: {no_dataset_count} 'no dataset' rows were excluded from duplicate review.\")\n",
    "print(f\"   You can mark these as valid automatically or review them separately.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51affe49",
   "metadata": {},
   "source": [
    "### Handle \"No Dataset\" Responses\n",
    "\n",
    "The cells below help you decide what to do with rows where no datasets were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze \"no dataset\" responses\n",
    "print(\"üìä 'No Dataset' Response Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get all no-dataset rows\n",
    "no_dataset_df = validation_df.iloc[no_dataset_rows]\n",
    "\n",
    "# Group by output_text pattern\n",
    "no_dataset_groups = no_dataset_df.groupby('output_text').size().sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nTotal 'no dataset' responses: {len(no_dataset_rows)}\")\n",
    "print(f\"Unique patterns: {len(no_dataset_groups)}\")\n",
    "\n",
    "print(f\"\\nüìã Top 5 patterns:\")\n",
    "for output_text, count in no_dataset_groups.head(5).items():\n",
    "    output_preview = str(output_text)[:100] + \"...\" if len(str(output_text)) > 100 else str(output_text)\n",
    "    print(f\"\\n  Pattern appears {count} times:\")\n",
    "    print(f\"  {output_preview}\")\n",
    "\n",
    "print(f\"\\nüí° Options:\")\n",
    "print(f\"  1. Keep ONE sample of each pattern for training (recommended)\")\n",
    "print(f\"  2. Keep ALL no-dataset responses (for training variety)\")\n",
    "print(f\"  3. Remove ALL no-dataset responses (if not needed)\")\n",
    "print(f\"\\nRun the appropriate cell below based on your choice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep ALL \"no dataset\" responses for training variety\n",
    "# These are already excluded from duplicate review, so no action needed!\n",
    "\n",
    "print(f\"üìä No-dataset response handling:\")\n",
    "print(f\"   Total no-dataset responses: {len(no_dataset_rows)}\")\n",
    "print(f\"   Action: KEEPING ALL for training variety\")\n",
    "print(f\"\\n‚úÖ All {len(no_dataset_rows)} no-dataset responses will be kept in the dataset\")\n",
    "print(f\"\\nüí° Note: These rows are already excluded from duplicate review.\")\n",
    "print(f\"   You will only review duplicates among real dataset extractions.\")\n",
    "print(f\"\\nüéØ No changes made to the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive duplicate review widget\n",
    "class DuplicateReviewer:\n",
    "    def __init__(self, df, duplicate_pairs):\n",
    "        self.df = df\n",
    "        self.duplicate_pairs = duplicate_pairs\n",
    "        self.current_pair_idx = 0\n",
    "        self.decisions = {}  # Maps (current_idx, past_idx) -> decision\n",
    "        \n",
    "        # Create widgets\n",
    "        self.output_area = widgets.Output()\n",
    "        \n",
    "        # New: buttons to mark which one is duplicate\n",
    "        self.mark_current_dup_btn = widgets.Button(\n",
    "            description=\"üî¥ Current is Duplicate\",\n",
    "            button_style='danger',\n",
    "            layout=widgets.Layout(width='220px', height='50px')\n",
    "        )\n",
    "        self.mark_past_dup_btn = widgets.Button(\n",
    "            description=\"üî¥ Previous is Duplicate\",\n",
    "            button_style='danger',\n",
    "            layout=widgets.Layout(width='220px', height='50px')\n",
    "        )\n",
    "        self.mark_both_dup_btn = widgets.Button(\n",
    "            description=\"üî¥ Both are Duplicates\",\n",
    "            button_style='danger',\n",
    "            layout=widgets.Layout(width='220px', height='50px')\n",
    "        )\n",
    "        \n",
    "        self.not_duplicate_btn = widgets.Button(\n",
    "            description=\"‚úÖ Not Duplicates\",\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px', height='50px')\n",
    "        )\n",
    "        self.skip_btn = widgets.Button(\n",
    "            description=\"‚è≠Ô∏è Skip for Now\",\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='200px', height='50px')\n",
    "        )\n",
    "        self.prev_btn = widgets.Button(\n",
    "            description=\"‚¨ÖÔ∏è Previous\",\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='150px', height='50px')\n",
    "        )\n",
    "        self.save_btn = widgets.Button(\n",
    "            description=\"üíæ Save Progress\",\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='200px', height='50px')\n",
    "        )\n",
    "        \n",
    "        # Progress label\n",
    "        self.progress_label = widgets.HTML()\n",
    "        \n",
    "        # Bind button actions\n",
    "        self.mark_current_dup_btn.on_click(self.mark_current_duplicate)\n",
    "        self.mark_past_dup_btn.on_click(self.mark_past_duplicate)\n",
    "        self.mark_both_dup_btn.on_click(self.mark_both_duplicate)\n",
    "        self.not_duplicate_btn.on_click(self.mark_not_duplicate)\n",
    "        self.skip_btn.on_click(self.skip)\n",
    "        self.prev_btn.on_click(self.previous)\n",
    "        self.save_btn.on_click(self.save_progress)\n",
    "        \n",
    "    def show_current_pair(self):\n",
    "        \"\"\"Display the current duplicate pair for review.\"\"\"\n",
    "        with self.output_area:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if self.current_pair_idx >= len(self.duplicate_pairs):\n",
    "                print(\"üéâ All duplicate pairs reviewed!\")\n",
    "                print(f\"\\nüìä Review Summary:\")\n",
    "                current_dup = sum(1 for v in self.decisions.values() if v == 'current_duplicate')\n",
    "                past_dup = sum(1 for v in self.decisions.values() if v == 'past_duplicate')\n",
    "                both_dup = sum(1 for v in self.decisions.values() if v == 'both_duplicate')\n",
    "                not_dup = sum(1 for v in self.decisions.values() if v == 'not_duplicate')\n",
    "                skipped = len(self.duplicate_pairs) - len(self.decisions)\n",
    "                \n",
    "                print(f\"   - Current marked as duplicate: {current_dup}\")\n",
    "                print(f\"   - Previous marked as duplicate: {past_dup}\")\n",
    "                print(f\"   - Both marked as duplicates: {both_dup}\")\n",
    "                print(f\"   - Not duplicates: {not_dup}\")\n",
    "                print(f\"   - Skipped: {skipped}\")\n",
    "                print(f\"\\n   Total rows to remove: {current_dup + past_dup + (both_dup * 2)}\")\n",
    "                print(\"\\nüíæ Don't forget to save your progress!\")\n",
    "                return\n",
    "            \n",
    "            current_idx, past_idx = self.duplicate_pairs[self.current_pair_idx]\n",
    "            current_row = self.df.iloc[current_idx]\n",
    "            past_row = self.df.iloc[past_idx]\n",
    "            \n",
    "            # Update progress\n",
    "            self.progress_label.value = f\"<h3 style='color: #2c3e50;'>Progress: {self.current_pair_idx + 1} / {len(self.duplicate_pairs)}</h3>\"\n",
    "            \n",
    "            # Compute word frequency differences\n",
    "            current_freq = count_word_frequencies(current_row['input_text'])\n",
    "            past_freq = count_word_frequencies(past_row['input_text'])\n",
    "            word_diffs = compare_word_frequencies(current_freq, past_freq)\n",
    "            \n",
    "            # Show comparison\n",
    "            html = format_comparison_html(current_row, past_row, word_diffs, current_idx, past_idx)\n",
    "            display(HTML(html))\n",
    "            \n",
    "            # Show any previous decision\n",
    "            pair_key = (current_idx, past_idx)\n",
    "            if pair_key in self.decisions:\n",
    "                prev_decision = self.decisions[pair_key]\n",
    "                if prev_decision == 'current_duplicate':\n",
    "                    print(f\"\\n‚ö†Ô∏è Previous decision: CURRENT marked as duplicate\")\n",
    "                elif prev_decision == 'past_duplicate':\n",
    "                    print(f\"\\n‚ö†Ô∏è Previous decision: PREVIOUS marked as duplicate\")\n",
    "                elif prev_decision == 'both_duplicate':\n",
    "                    print(f\"\\n‚ö†Ô∏è Previous decision: BOTH marked as duplicates\")\n",
    "                elif prev_decision == 'not_duplicate':\n",
    "                    print(f\"\\n‚ö†Ô∏è Previous decision: NOT DUPLICATES\")\n",
    "    \n",
    "    def mark_current_duplicate(self, b):\n",
    "        \"\"\"Mark current row as duplicate and move to next.\"\"\"\n",
    "        if self.current_pair_idx < len(self.duplicate_pairs):\n",
    "            pair = self.duplicate_pairs[self.current_pair_idx]\n",
    "            self.decisions[pair] = 'current_duplicate'\n",
    "            current_idx, _ = pair\n",
    "            self.df.loc[current_idx, 'is_duplicate'] = True\n",
    "            self.df.loc[current_idx, 'notes'] = 'Duplicate (current row)'\n",
    "            self.current_pair_idx += 1\n",
    "            self.show_current_pair()\n",
    "    \n",
    "    def mark_past_duplicate(self, b):\n",
    "        \"\"\"Mark past row as duplicate and move to next.\"\"\"\n",
    "        if self.current_pair_idx < len(self.duplicate_pairs):\n",
    "            pair = self.duplicate_pairs[self.current_pair_idx]\n",
    "            self.decisions[pair] = 'past_duplicate'\n",
    "            _, past_idx = pair\n",
    "            self.df.loc[past_idx, 'is_duplicate'] = True\n",
    "            self.df.loc[past_idx, 'notes'] = 'Duplicate (previous row)'\n",
    "            self.current_pair_idx += 1\n",
    "            self.show_current_pair()\n",
    "    \n",
    "    def mark_both_duplicate(self, b):\n",
    "        \"\"\"Mark both rows as duplicates and move to next.\"\"\"\n",
    "        if self.current_pair_idx < len(self.duplicate_pairs):\n",
    "            pair = self.duplicate_pairs[self.current_pair_idx]\n",
    "            self.decisions[pair] = 'both_duplicate'\n",
    "            current_idx, past_idx = pair\n",
    "            self.df.loc[current_idx, 'is_duplicate'] = True\n",
    "            self.df.loc[current_idx, 'notes'] = 'Duplicate (both rows)'\n",
    "            self.df.loc[past_idx, 'is_duplicate'] = True\n",
    "            self.df.loc[past_idx, 'notes'] = 'Duplicate (both rows)'\n",
    "            self.current_pair_idx += 1\n",
    "            self.show_current_pair()\n",
    "    \n",
    "    def mark_not_duplicate(self, b):\n",
    "        \"\"\"Mark pair as not duplicate and move to next.\"\"\"\n",
    "        if self.current_pair_idx < len(self.duplicate_pairs):\n",
    "            pair = self.duplicate_pairs[self.current_pair_idx]\n",
    "            self.decisions[pair] = 'not_duplicate'\n",
    "            current_idx, past_idx = pair\n",
    "            self.df.loc[current_idx, 'is_duplicate'] = False\n",
    "            self.df.loc[past_idx, 'is_duplicate'] = False\n",
    "            self.current_pair_idx += 1\n",
    "            self.show_current_pair()\n",
    "    \n",
    "    def skip(self, b):\n",
    "        \"\"\"Skip current pair and move to next.\"\"\"\n",
    "        self.current_pair_idx += 1\n",
    "        self.show_current_pair()\n",
    "    \n",
    "    def previous(self, b):\n",
    "        \"\"\"Go back to previous pair.\"\"\"\n",
    "        if self.current_pair_idx > 0:\n",
    "            self.current_pair_idx -= 1\n",
    "            self.show_current_pair()\n",
    "    \n",
    "    def save_progress(self, b):\n",
    "        \"\"\"Save current progress to Excel file.\"\"\"\n",
    "        with self.output_area:\n",
    "            print(\"\\nüíæ Saving progress...\")\n",
    "            try:\n",
    "                self.df.to_excel(excel_output_path, index=False, engine='openpyxl')\n",
    "                print(f\"‚úÖ Progress saved to {excel_output_path}\")\n",
    "                \n",
    "                # Save decisions log\n",
    "                decisions_log_path = excel_output_path.replace('.xlsx', '_duplicate_decisions.json')\n",
    "                with open(decisions_log_path, 'w') as f:\n",
    "                    # Convert tuple keys to strings for JSON serialization\n",
    "                    json_decisions = {f\"{k[0]}_{k[1]}\": v for k, v in self.decisions.items()}\n",
    "                    json.dump(json_decisions, f, indent=2)\n",
    "                print(f\"‚úÖ Decisions log saved to {decisions_log_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error saving: {e}\")\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the review interface.\"\"\"\n",
    "        self.show_current_pair()\n",
    "        \n",
    "        # Row 1: Mark duplicate buttons\n",
    "        dup_button_box = widgets.HBox(\n",
    "            [self.mark_current_dup_btn, self.mark_past_dup_btn, self.mark_both_dup_btn],\n",
    "            layout=widgets.Layout(justify_content='center', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        # Row 2: Other action buttons\n",
    "        action_button_box = widgets.HBox(\n",
    "            [self.not_duplicate_btn, self.skip_btn],\n",
    "            layout=widgets.Layout(justify_content='center', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        # Row 3: Control buttons\n",
    "        control_box = widgets.HBox(\n",
    "            [self.prev_btn, self.save_btn],\n",
    "            layout=widgets.Layout(justify_content='center', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        display(self.progress_label)\n",
    "        display(self.output_area)\n",
    "        display(dup_button_box)\n",
    "        display(action_button_box)\n",
    "        display(control_box)\n",
    "\n",
    "print(\"‚úÖ DuplicateReviewer class loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3c1f1",
   "metadata": {},
   "source": [
    "### Start Duplicate Review\n",
    "\n",
    "Run the cell below to start the interactive duplicate review process.\n",
    "\n",
    "**How to use:**\n",
    "- Review each pair carefully\n",
    "- Check the **word frequency differences** to see how input texts differ\n",
    "- Read the **input text comparison** (first 500 characters shown)\n",
    "- The **output text is identical** for both rows (that's why they're flagged)\n",
    "- Decide which row(s) to keep or remove:\n",
    "  - üî¥ **Current is Duplicate**: Mark the current (top) row as duplicate - will be removed\n",
    "  - üî¥ **Previous is Duplicate**: Mark the previous (bottom) row as duplicate - will be removed\n",
    "  - üî¥ **Both are Duplicates**: Mark both rows as duplicates - both will be removed\n",
    "  - ‚úÖ **Not Duplicates**: Keep both rows - they have different contexts despite same output\n",
    "  - ‚è≠Ô∏è **Skip for Now**: Unsure, will review later\n",
    "- Use ‚¨ÖÔ∏è **Previous** to go back and review earlier pairs\n",
    "- Click üíæ **Save Progress** frequently to preserve your work!\n",
    "\n",
    "**Tip:** Usually you'll want to mark just one as duplicate (keep the better quality one), but sometimes both might be poor quality and you'll want to mark both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the duplicate review process\n",
    "if len(duplicate_pairs) > 0:\n",
    "    reviewer = DuplicateReviewer(validation_df, duplicate_pairs)\n",
    "    reviewer.display()\n",
    "else:\n",
    "    print(\"‚úÖ No duplicate pairs found! Your dataset is clean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d521499",
   "metadata": {},
   "source": [
    "### Post-Review Analysis\n",
    "\n",
    "After reviewing duplicates, use the cells below to analyze and clean your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0926737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data if you're returning to the notebook after saving\n",
    "# validation_df = pd.read_excel(excel_output_path)\n",
    "\n",
    "# Show duplicate review statistics\n",
    "print(\"üìä Duplicate Review Statistics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'is_duplicate' in validation_df.columns:\n",
    "    duplicate_counts = validation_df['is_duplicate'].value_counts(dropna=False)\n",
    "    print(f\"Marked as duplicates: {duplicate_counts.get(True, 0)}\")\n",
    "    print(f\"Marked as not duplicates: {duplicate_counts.get(False, 0)}\")\n",
    "    print(f\"Not yet reviewed: {duplicate_counts.get(None, 0) if None in duplicate_counts.index else validation_df['is_duplicate'].isna().sum()}\")\n",
    "    print(f\"\\nTotal rows: {len(validation_df)}\")\n",
    "    \n",
    "    # Show rows marked as duplicates\n",
    "    duplicates = validation_df[validation_df['is_duplicate'] == True]\n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"\\nüîç Rows marked as duplicates ({len(duplicates)} rows):\")\n",
    "        print(duplicates[['custom_id', 'article_id', 'section_title', 'output_text']].head(10))\n",
    "else:\n",
    "    print(\"No duplicate review has been performed yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from dataset\n",
    "# Run this cell after completing your duplicate review\n",
    "\n",
    "if 'is_duplicate' in validation_df.columns:\n",
    "    # Create clean dataset by removing rows marked as duplicates\n",
    "    clean_df = validation_df[validation_df['is_duplicate'] != True].copy()\n",
    "    \n",
    "    print(f\"üìä Dataset Cleaning Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Original dataset size: {len(validation_df)} rows\")\n",
    "    print(f\"Rows marked as duplicates: {(validation_df['is_duplicate'] == True).sum()}\")\n",
    "    print(f\"Clean dataset size: {len(clean_df)} rows\")\n",
    "    print(f\"Reduction: {len(validation_df) - len(clean_df)} rows ({((len(validation_df) - len(clean_df)) / len(validation_df) * 100):.2f}%)\")\n",
    "    \n",
    "    # Save clean dataset\n",
    "    clean_output_path = excel_output_path.replace('.xlsx', '_clean.xlsx')\n",
    "    clean_df.to_excel(clean_output_path, index=False, engine='openpyxl')\n",
    "    print(f\"\\n‚úÖ Clean dataset saved to: {clean_output_path}\")\n",
    "    \n",
    "    # Update validation_df to use clean version\n",
    "    # validation_df = clean_df\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No duplicate review has been performed yet. Run the duplicate detection cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
