{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567557dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gatherer.data_gatherer import DataGatherer\n",
    "import pandas as pd\n",
    "from data_gatherer.llm.response_schema import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGatherer(log_level=\"INFO\", load_from_cache=False, save_to_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"scripts/NYC Open Data/NYC Open Data - Benchmark - paper-dataset.csv\")\n",
    "prompt_name = \"GPT_F2DR_FewShot_Descr\"\n",
    "subdir='metadata_prompts'\n",
    "response_schema = autoDDG_from_context_schema\n",
    "grobid_for_pdf=True\n",
    "FDR=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef43836",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    paper_link = row['Paper']\n",
    "    if paper_link not in todo:\n",
    "        continue\n",
    "    title = row['Title']\n",
    "    link = row['Link']\n",
    "    dataset_details = f\"Title: {title}\\nLink: {link}\"\n",
    "    dg.logger.info(f\"Target Dataset Details: {dataset_details}\")\n",
    "    full_text = dg.fetch_data(paper_link)\n",
    "    dg.init_parser_by_input_type(dg.data_fetcher.raw_data_format, raw_data = full_text, grobid_for_pdf = grobid_for_pdf, full_document_read=FDR)\n",
    "    src_cont = dg.normalize_fulltext_input(full_text)\n",
    "    article_id = dg.data_fetcher.url_to_article_id(paper_link)\n",
    "    dg.logger.info(f\"Processing article ID: {article_id}\")\n",
    "    dataset_info = dg.parser.extract_dataset_description(src_cont, dataset_details, subdir=subdir, prompt_name=prompt_name, response_schema=response_schema, article_id=article_id)[0]\n",
    "    # add to each row the extracted description\n",
    "    df.at[index, 'Extracted Description'] = dataset_info.get('dataset_description', '')\n",
    "    df.at[index, 'reuse_potential'] = dataset_info.get('reuse_potential', '')\n",
    "    df.at[index, 'citation_type'] = dataset_info.get('citation_type', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3eb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sub to transform any format to plain text\n",
    "df.to_csv(\"scripts/NYC Open Data/NYC Open Data - Benchmark - paper-dataset-with-descriptions-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Paper'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01376a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
