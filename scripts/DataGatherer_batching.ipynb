{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:30:53.289617Z",
     "start_time": "2025-09-04T16:30:29.500758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from data_gatherer.data_gatherer import DataGatherer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2b2bc4106d2ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:15.898169Z",
     "start_time": "2025-09-04T16:31:15.880961Z"
    }
   },
   "outputs": [],
   "source": [
    "input_file = \"scripts/exp_input/sage_input.txt\"\n",
    "fname = \"prompts/prompts_1.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca05a29b7c100d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:17.295747Z",
     "start_time": "2025-09-04T16:31:17.291744Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gemini-2.0-flash\"  # \"gemini-2.0-flash\" or \"gpt-4o-mini\"\n",
    "prompt = \"GPT_FDR_FewShot_Syn\"  # \"GPT_from_full_input_Examples\" or \"GPT_FewShot\"\n",
    "FDR = True\n",
    "semantic_retrieval = False\n",
    "section_filter= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae25cbd54d4fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:19.865917Z",
     "start_time": "2025-09-04T16:31:19.860295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PMCIDs: 1316\n"
     ]
    }
   ],
   "source": [
    "# write list to a text file\n",
    "with open(input_file, 'r') as f:\n",
    "    pmcids = f.read().splitlines()\n",
    "\n",
    "print(\"Number of PMCIDs:\", len(pmcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79cbd7265b497e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:22.492692Z",
     "start_time": "2025-09-04T16:31:22.479800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[97mdata_gatherer.py - line 301 - INFO - Setting up data fetcher...\u001b[0m\n",
      "\u001b[97mdata_fetcher.py - line 33 - INFO - Loaded 2190 publications from local DataFrame.\u001b[0m\n",
      "\u001b[97mdata_gatherer.py - line 331 - INFO - Data fetcher setup completed.\u001b[0m\n",
      "\u001b[97mdata_gatherer.py - line 103 - INFO - DataGatherer orchestrator initialized. Extraction Model: gemini-2.5-flash\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dg = DataGatherer(\n",
    "    llm_name=model_name, \n",
    "    log_level='INFO', \n",
    "    process_entire_document=FDR, \n",
    "    driver_path=None, \n",
    "    save_to_cache=True, \n",
    "    load_from_cache=True,\n",
    "    full_output_file=\"scripts/output/result.csv\"\n",
    ") #, save_dynamic_prompts=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d91d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch\n",
    "raw_data = dg.fetch_data(\n",
    "    urls=pmcids\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac4139",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/batch#1-preparing-your-batch-file\n",
    "\n",
    "https://portkey.ai/docs/integrations/llms/bedrock/batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ececd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse and return prompts JSONL\n",
    "for url,item in raw_data.items():\n",
    "    raw_data_format = item['raw_data_format']\n",
    "    fetched_data = item['fetched_data']\n",
    "    print(f\"Processing {url} with format {raw_data_format}...\")\n",
    "    jsonl_cont = dg.DRAFT_prepare_prompts_batch(\n",
    "        fetched_data=fetched_data,\n",
    "        raw_data_format=raw_data_format,\n",
    "        prompt=prompt,\n",
    "        FDR=FDR,\n",
    "        semantic_retrieval=semantic_retrieval,\n",
    "        section_filter=section_filter,\n",
    "        fname=fname\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file info like size and number of lines\n",
    "file_size = os.path.getsize(fname)\n",
    "num_lines = sum(1 for line in open(fname))\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "print(f\"Number of lines: {num_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67754f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to AWS S3\n",
    "import boto3\n",
    "\n",
    "# setup client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# define target bucket and object name\n",
    "bucket_name = 'vida-llm'\n",
    "object_key = os.path.basename(fname)\n",
    "local_file_path = fname\n",
    "\n",
    "# upload the file\n",
    "s3.upload_file(\n",
    "    Filename=local_file_path,\n",
    "    Bucket=bucket_name,\n",
    "    Key=object_key,\n",
    "    ExtraArgs={'ContentType': 'application/json'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d307d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025_arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
