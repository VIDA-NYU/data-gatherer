{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:30:53.289617Z",
     "start_time": "2025-09-04T16:30:29.500758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "from data_gatherer.data_gatherer import DataGatherer\n",
    "import pandas as pd\n",
    "from data_gatherer.llm.response_schema import *\n",
    "from data_gatherer.parser.xml_parser import XMLParser\n",
    "from scripts.experiment_utils import evaluate_performance\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2b2bc4106d2ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:15.898169Z",
     "start_time": "2025-09-04T16:31:15.880961Z"
    }
   },
   "outputs": [],
   "source": [
    "input_file = \"scripts/exp_input/REV.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca05a29b7c100d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:17.295747Z",
     "start_time": "2025-09-04T16:31:17.291744Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt-5-mini\"  # \"gemini-2.0-flash\" or \"gpt-4o-mini\"\n",
    "prompt = \"GPT_FewShot\"  # \"GPT_from_full_input_Examples\" or \"GPT_FewShot\"\n",
    "FDR = False\n",
    "semantic_retrieval = False\n",
    "brute_force_RegEx_ID_ptrs = False\n",
    "section_filter= \"supplementary_material\"\n",
    "top_k = 0\n",
    "\n",
    "batch_file_path=f'scripts/tmp/batch_requests_openai_RTR-{top_k}_DataRef-REV.jsonl'\n",
    "ret_file=f'scripts/output/semantic_search/resp_RTR_{top_k}.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae25cbd54d4fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:19.865917Z",
     "start_time": "2025-09-04T16:31:19.860295Z"
    }
   },
   "outputs": [],
   "source": [
    "# write list to a text file\n",
    "with open(input_file, 'r') as f:\n",
    "    pmcids = f.read().splitlines()\n",
    "\n",
    "print(\"Number of PMCIDs:\", len(pmcids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed88b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_urls = pmcids  # For testing, limit to first 10 PMCIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cbd7265b497e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T16:31:22.492692Z",
     "start_time": "2025-09-04T16:31:22.479800Z"
    }
   },
   "outputs": [],
   "source": [
    "dg = DataGatherer(\n",
    "    llm_name=model_name, \n",
    "    log_level='INFO', \n",
    "    process_entire_document=FDR, \n",
    "    driver_path=None, \n",
    "    save_to_cache=False, \n",
    "    load_from_cache=False,\n",
    "    embeds_cache_read=True,\n",
    "    embeds_cache_write=True,\n",
    ") #, save_dynamic_prompts=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac4139",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/batch#1-preparing-your-batch-file\n",
    "\n",
    "https://portkey.ai/docs/integrations/llms/bedrock/batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ececd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_openai = dg.run_integrated_batch_processing(\n",
    "    url_list=pmcids,\n",
    "    batch_file_path=batch_file_path,\n",
    "    api_provider='openai',  # Uses OpenAI batch API for 50% cost discount\n",
    "    prompt_name=\"GPT_FewShot\",\n",
    "    response_format=dataset_response_schema_gpt,\n",
    "    semantic_retrieval=semantic_retrieval,\n",
    "    section_filter=section_filter,\n",
    "    top_k=top_k,\n",
    "    submit_immediately=False,\n",
    "    wait_for_completion=False,  # Set to True if you want to wait for results\n",
    "    batch_description=\"DATA-REF REV retrieval with OpenAI API\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_filepath = 'scripts/tmp/batch_requests_openai_RTR-1_DataRef-REV.jsonl'\n",
    "prompts_load = []\n",
    "with open(prompts_filepath, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            prompts_load.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_parquet(\"scripts/output/gold/dataset_citation_records_Table.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b12a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_avg = 0\n",
    "n_dfs = len(prompts_load)\n",
    "\n",
    "for prompt in prompts_load:\n",
    "    pmc_id = dg.data_fetcher.url_to_article_id(prompt['custom_id'])\n",
    "    gt = df_gt[df_gt['pmcid'] == pmc_id]\n",
    "    datasets_gt = gt['identifier'].values.tolist()\n",
    "    #print(f\"datasets: {datasets_gt}\")\n",
    "    body_msg = [item['content'] for item in prompt['body']['input']]\n",
    "    #print (f\"prompt: {body_msg}\")\n",
    "    input_cont_str = \"\\n\".join(body_msg)\n",
    "\n",
    "    datasets_found, datasets_tot = 0, len(datasets_gt)\n",
    "    for dataset in datasets_gt:\n",
    "        if dataset.lower() in input_cont_str.lower():\n",
    "            datasets_found += 1\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Missing dataset {dataset} in prompt for pmcid {pmc_id}\")\n",
    "    found_i = datasets_found / datasets_tot if datasets_tot > 0 else 1.0\n",
    "    found_avg += found_i/n_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chunking and submission - NO monitoring or result combination\n",
    "result = dg.split_jsonl_and_submit(\n",
    "    batch_file_path=batch_file_path,\n",
    "    max_file_size_mb=200.0,\n",
    "    api_provider='openai',\n",
    "    wait_between_submissions=30,\n",
    "    batch_description=f\"Chunked RTR DataRef-REV batch processing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for file_path in ['scripts/tmp/batch_requests_openai_all_SAGE_chunk_002.jsonl','scripts/tmp/batch_requests_openai_all_SAGE_chunk_003.jsonl']:\n",
    "    dg.parser.llm_client.submit_batch_job(\n",
    "                        file_path, \n",
    "                        api_provider='openai',\n",
    "                        batch_description= f'file_path: {file_path}'\n",
    "    )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78727a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = 'batch_68efcceeb7448190ae19cc890a87aef8'\n",
    "batch_id_1 = 'batch_68efcf6f0c0081909cce95c57d4aa55d'\n",
    "batch_id_2 = 'batch_68efcf7e0dd881909f000e1634efc368'\n",
    "\n",
    "batch_id_REV_RTR_9 = 'batch_6914c7be180481909752dd682ab730fb'\n",
    "batch_id_REV_RTR_5 = 'batch_6914a7de95248190b2d5d444d827373f'\n",
    "batch_id_REV_RTR_1 = 'batch_6914d280310c819082bed1fa3d661f22'\n",
    "batch_id_REV_RTR_ptr = 'batch_6915049af5008190a695c4284413d692'\n",
    "\n",
    "batch_id_REV_RTR_base = 'batch_6916b7d814cc8190a4ca76844ad4f58d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dg.parser:\n",
    "    dg.parser = XMLParser(open_data_repos_ontology=\"open_bio_data_repos.json\", logger=dg.logger,\n",
    "    llm_name=dg.llm)\n",
    "\n",
    "res = dg.parser.llm_client.download_batch_results(\n",
    "    batch_id=batch_id_REV_RTR_base,\n",
    "    output_file_path='scripts/tmp/resp_RTR_base.jsonl',\n",
    "    api_provider='openai'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Combine multiple batch result files into one\n",
    "import json\n",
    "\n",
    "# List of result files to combine\n",
    "result_files = [\n",
    "    'scripts/tmp/res_1.jsonl',\n",
    "    'scripts/tmp/res_2.jsonl',\n",
    "    'scripts/tmp/res_3.jsonl'\n",
    "]\n",
    "\n",
    "# Output combined file\n",
    "combined_output = 'scripts/tmp/combined_batch_results.jsonl'\n",
    "\n",
    "# Combine all JSONL files\n",
    "all_results = []\n",
    "total_lines = 0\n",
    "\n",
    "for file_path in result_files:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Reading {file_path}...\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            file_lines = 0\n",
    "            for line in f:\n",
    "                if line.strip():  # Skip empty lines\n",
    "                    all_results.append(line.strip())\n",
    "                    file_lines += 1\n",
    "                    total_lines += 1\n",
    "        print(f\"  ‚Üí Added {file_lines} lines from {file_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: File not found - {file_path}\")\n",
    "\n",
    "# Write combined results to new file\n",
    "print(f\"\\nWriting {total_lines} total lines to {combined_output}...\")\n",
    "with open(combined_output, 'w', encoding='utf-8') as f:\n",
    "    for line in all_results:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Combined batch results saved to: {combined_output}\")\n",
    "print(f\"üìä Total lines combined: {total_lines}\")\n",
    "\n",
    "# Verify the combined file\n",
    "file_size_mb = os.path.getsize(combined_output) / 1024 / 1024\n",
    "print(f\"üìÅ Combined file size: {file_size_mb:.2f} MB\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dg.parser is None:\n",
    "    dg.parser = XMLParser(dg.open_data_repos_ontology, dg.logger, llm_name=dg.llm)\n",
    "\n",
    "with open('scripts/tmp/resp_RTR_base.jsonl', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(f\"Number of lines in combined file: {len(lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_file = 'scripts/output/semantic_search/resp_RTR_base.csv'\n",
    "ret_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed71d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = dg.from_batch_resp_file_to_df('scripts/tmp/resp_RTR_base.jsonl', output_file_path=ret_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(ret_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c800f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcids_ret = set([re.sub('(https://www.ncbi.nlm.nih.gov/pmc/articles/.*)/','\\\\1',item).lower() for item in res_df['source_url'].to_list()])\n",
    "pmcids = set([idx.lower() for idx in pmcids])\n",
    "missing_urls = list(pmcids - pmcids_ret)\n",
    "len(missing_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607c0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets_append = dg.process_articles(\n",
    "    missing_urls,\n",
    "    prompt_name=\"GPT_FewShot\",\n",
    "    full_document_read=FDR,\n",
    "    top_k = top_k,\n",
    "    semantic_retrieval=semantic_retrieval,\n",
    "    section_filter= section_filter,\n",
    "    response_format=dataset_response_schema_gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cd4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_datasets_append), type(new_datasets_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf81940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# union dataframes\n",
    "for pmc_link in new_datasets_append.keys():\n",
    "    final_df = pd.concat([res_df, new_datasets_append[pmc_link]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e439a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(ret_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open('/Users/pietro/Downloads/batch_68ed8a97bf98819090f2cb62841f0219_error.jsonl') as f:\n",
    "    error_lines = f.readlines()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a269a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_parquet('scripts/output/gold/dataset_citation_records_Table.parquet')\n",
    "gt.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f612693",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(ret_file)\n",
    "res_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_url_to_article_id(row):\n",
    "    if row['source_url'].endswith('/'):\n",
    "        return row['source_url'][:-1]\n",
    "    return row['source_url']\n",
    "\n",
    "res_df['source_url'] = res_df.apply(map_url_to_article_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_performance(\n",
    "    res_df,\n",
    "    gt,\n",
    "    dg,\n",
    "    'scripts/output/false_positives.txt', \n",
    "    false_negatives_file='scripts/output/false_negatives.txt',\n",
    "    repo_return=True,\n",
    "    gt_base = pmcids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55703e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa15f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
