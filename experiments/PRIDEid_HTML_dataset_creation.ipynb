{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-16T04:35:29.943062Z",
     "start_time": "2025-02-16T04:35:25.161712Z"
    }
   },
   "source": [
    "# import from the files in this directory\n",
    "from dotenv import load_dotenv\n",
    "from classifier import *\n",
    "from data_fetcher import *\n",
    "from parser import *\n",
    "from orchestrator import *\n",
    "from logger_setup import *\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T04:35:33.831112Z",
     "start_time": "2025-02-16T04:35:29.944629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = 'config_experiment.json'  # Config with input file details\n",
    "load_dotenv()\n",
    "orchestrator = Orchestrator(config_path)"
   ],
   "id": "d38134199deb3f48",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "orchestrator.py - line 20 - INFO - Data_Gatherer Orchestrator initialized. Extraction step Model: gemini-2.0-flash-exp\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T04:36:40.602402Z",
     "start_time": "2025-02-16T04:36:38.349842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "urls = None\n",
    "df = pd.read_csv('exp_input/proteomexchange_search.tsv', sep='\\t')\n",
    "publication_datasets = df[['publication','identifier','repository']]"
   ],
   "id": "b77c99b6f6d3319",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# get an idea of values in df publication\n",
    "publication_datasets['publication'].value_counts()"
   ],
   "id": "5b6d73f5cec35e38",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#  clean the `publication` column by filtering out unwanted values like `\"Dataset with its publication pending\"`, `\"no publication\"`, and any HTML tags. \n",
    "# Remove rows with unwanted values\n",
    "filtered_df = publication_datasets[~publication_datasets['publication'].isin([\"Dataset with its publication pending\", \"no publication\"])]\n",
    "filtered_df[381:]"
   ],
   "id": "5ef8385ef9b8416d",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Assuming filtered_df is already defined\n",
    "filtered_df['publication_link'] = None  # Create a new column for the links\n",
    "\n",
    "for i, row in filtered_df.iterrows():\n",
    "    pub = str(row['publication'])  # Ensure string type\n",
    "    if \"href\" in pub:\n",
    "        match = re.findall(r'href=[\\'\"]([^\\'\"]+)[\\'\"]', pub)\n",
    "        if match:\n",
    "            filtered_df.at[i, 'publication_link'] = match  # Assign all the matched URLs\n",
    "        else:\n",
    "            filtered_df.at[i, 'publication_link'] = None\n",
    "    else:\n",
    "        filtered_df.at[i, 'publication_link'] = None\n",
    "\n",
    "# Drop rows with missing links (optional)\n",
    "filtered_df.dropna(subset=['publication_link'], inplace=True)\n",
    "filtered_df.reset_index(drop=True, inplace=True)"
   ],
   "id": "ac053d4c4e0d95e6",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "m = 0\n",
    "for i,row in filtered_df.iterrows():\n",
    "    id = row['identifier']\n",
    "    m+=len(row['publication_link'])\n",
    "print(m/i+1)\n",
    "print(filtered_df)"
   ],
   "id": "bf9d75490f3125de",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data = []\n",
    "\n",
    "start = 441\n",
    "\n",
    "iter_max = 50\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i,row in filtered_df[start:].iterrows():\n",
    "    \n",
    "    driver = orchestrator.setup_data_fetcher()\n",
    "        \n",
    "    id = row['identifier']\n",
    "    \n",
    "    if i == 441 + iter_max:\n",
    "        break\n",
    "        \n",
    "    if i%100 == 0 and i>0:\n",
    "        print(f\"Progress {i+1}/{len(filtered_df)}. ETA {((time.time()-t0)/(i+1))*(len(filtered_df)-i-1)}\")\n",
    "        \n",
    "    print(f\"Processing URL {i+1}.\\nTime elapsed: {time.time()-t0}\") if i>0 else None\n",
    "    print(f\"{len(row['publication_link'])} links found for dataset {id}\")\n",
    "    \n",
    "\n",
    "    for url in row['publication_link']:\n",
    "        orchestrator.logger.info(f\"Processing URL: {url}\")\n",
    "    \n",
    "        orchestrator.current_url = url\n",
    "        orchestrator.publisher = orchestrator.data_fetcher.url_to_publisher_domain(url)\n",
    "        \n",
    "        orchestrator.data_fetcher = orchestrator.data_fetcher.update_DataFetcher_settings(url, orchestrator.full_DOM, orchestrator.logger)\n",
    "        \n",
    "        try:\n",
    "            orchestrator.logger.info(\"Fetching Raw content\")\n",
    "            raw_data = orchestrator.data_fetcher.fetch_data(url)\n",
    "            if id in raw_data:\n",
    "                data.append({\"publication\": url,\"dataset_uid\": row['identifier'], \"repo_name\": row['repository'], \"raw_html\": raw_data})\n",
    "                break\n",
    "            else:\n",
    "                print(\"id not found in raw data\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            orchestrator.logger.error(f\"Error processing URL {url}: {e}\", exc_info=True)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(\"publication\",inplace=True)\n",
    "df"
   ],
   "id": "749a6cf1e6facd65",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.set_index(\"publication\",inplace=True)\n",
    "df"
   ],
   "id": "bec4b1957c80d246",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df_old = pd.read_csv(\"exp_input/raw_data.csv\", index_col=\"publication\")\n",
    "print(df_old.shape)\n",
    "# append rows to the existing CSV\n",
    "df_new = pd.concat([df_old,df])\n",
    "df_new.to_csv(\"exp_input/PRIDEid_HTML_data.csv\")"
   ],
   "id": "66b46bebd3829d70",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 12,
   "source": "df_new.shape",
   "id": "c0b24ab169f53dfe",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(len(df_new.index))\n",
    "print(len(df_new.index.unique()))"
   ],
   "id": "2c456519e5c167fd",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df_merged = (\n",
    "    df_new.reset_index()\n",
    "    .groupby('publication')\n",
    "    .agg({\n",
    "        'dataset_uid': lambda x: ','.join(sorted(set(x))),  # Concatenate unique dataset_uids\n",
    "        'repo_name': lambda x: ','.join(sorted(set(x))),   # Concatenate unique repo_names\n",
    "        'raw_html': 'first'  # Keep the first raw_html\n",
    "    })\n",
    ")"
   ],
   "id": "27afb2c289dcbf5",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "df_merged.to_csv(\"exp_input/raw_data.csv\")",
   "id": "d76d0ff6397fb4b4",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 24,
   "source": "df_merged",
   "id": "105c7cdafc44a05b",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
